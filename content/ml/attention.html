

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Attention &#8212; notes</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/ml/attention';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="View Synthesis" href="view_synthesis.html" />
    <link rel="prev" title="Theory" href="theory.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.svg" class="logo__image only-light" alt="notes - Home"/>
    <script>document.write(`<img src="../../_static/logo.svg" class="logo__image only-dark" alt="notes - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../inference/intro.html">Inference/sampling</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../inference/mcmc.html">Markov chain Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inference/vi.html">Variational inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inference/inla.html">INLA (integrated nested Laplace approximation)</a></li>

</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/intro.html">Algorithms</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../astrophysics/intro.html">Astrophysics</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../astrophysics/comments.html">Astrophysics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../astrophysics/stars.html">Stars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../astrophysics/cosmology.html">Cosmology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../astrophysics/proposals.html">Writing proposals</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../statistics/intro.html">Statistics</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../statistics/measure_theory.html">Measure Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statistics/stochastic.html">Stochastic Calculus</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Machine Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="theory.html">Theory</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Attention</a></li>


<li class="toctree-l2"><a class="reference internal" href="view_synthesis.html">View Synthesis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/index.html">Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/bayesboot.html">Bayesian Bootstrapping</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notebooks/neural_pde.html">Neural PDEs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../talks/index.html">Talks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/al-jshen/notes" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/al-jshen/notes/issues/new?title=Issue%20on%20page%20%2Fcontent/ml/attention.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/ml/attention.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Attention</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Attention</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-is-all-you-need-vaswani2017">Attention is all you need <span class="xref cite cite-p">Vaswani2017</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-variants">Attention variants</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#vision-transformers">Vision Transformers</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vision-transformers-dosovitskiy2021">Vision Transformers <span class="xref cite cite-p">Dosovitskiy2021</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#axial-attention-ho2019">Axial attention <span class="xref cite cite-p">Ho2019</span></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">Pre-training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#emergent-properties-in-self-supervised-vision-transformers-caron2021">Emergent properties in self-supervised vision transformers <span class="xref cite cite-p">Caron2021</span></a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="attention">
<h1>Attention<a class="headerlink" href="#attention" title="Permalink to this heading">#</a></h1>
<section id="attention-is-all-you-need-vaswani2017">
<h2>Attention is all you need <span id="id1">[<a class="reference internal" href="#id509" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. 2017. URL: http://arxiv.org/abs/1706.03762 (visited on 2023-10-14), arXiv:1706.03762.">Vaswani <em>et al.</em>, 2017</a>]</span><a class="headerlink" href="#attention-is-all-you-need-vaswani2017" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>attention is a mechanism that allows a model to focus on relevant parts of the input</p>
<div class="amsmath math notranslate nohighlight" id="equation-efde5faf-37d4-4a84-8548-a41fa8fa6bd4">
<span class="eqno">(31)<a class="headerlink" href="#equation-efde5faf-37d4-4a84-8548-a41fa8fa6bd4" title="Permalink to this equation">#</a></span>\[\begin{align}
  \text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
  \end{align}\]</div>
</li>
<li><p>attention maps can be pulled out of the model after the softmax and visualized to see which parts of the input the model is focusing on</p></li>
<li><p>multi-head attention (MHA) splits the input into multiple heads and applies attention to each of them in parallel, then concatenates the outputs and projects them back down to the original dimension, allowing you to focus on information from multiple representation subspaces at once</p></li>
<li><p>self-attention is attention where <span class="math notranslate nohighlight">\(Q\)</span>, <span class="math notranslate nohighlight">\(K\)</span>, and <span class="math notranslate nohighlight">\(V\)</span> are all the same</p></li>
<li><p>attention is permutation invariant, so you need to add positional encodings to the input if you want to preserve order</p></li>
<li><p>implementation in PyTorch: use <code class="docutils literal notranslate"><span class="pre">F.scaled_dot_product_attention</span></code>, which attends over the second last dimension (the other dimensions can be whatever you want)</p></li>
<li><p>standard flow: embed input, add positional encodings, pass through Transformer blocks, pass through output head</p></li>
</ul>
</section>
<section id="attention-variants">
<h2>Attention variants<a class="headerlink" href="#attention-variants" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>ReAttention <span id="id2">[<a class="reference internal" href="#id542" title="Daquan Zhou, Bingyi Kang, Xiaojie Jin, Linjie Yang, Xiaochen Lian, Zihang Jiang, Qibin Hou, and Jiashi Feng. DeepViT: Towards Deeper Vision Transformer. April 2021. URL: http://arxiv.org/abs/2103.11886 (visited on 2023-12-21), arXiv:2103.11886.">Zhou <em>et al.</em>, 2021</a>]</span>: mix the attention head outputs with a linear layer (after softmax) before multiplying with values, which solves the problem of attention collapse, which is when (deep) ViTs learn attention maps that are similar to each other and so do not scale well with depth</p>
<div class="amsmath math notranslate nohighlight" id="equation-9fea047d-6e59-492e-8c1a-58d24c21f675">
<span class="eqno">(32)<a class="headerlink" href="#equation-9fea047d-6e59-492e-8c1a-58d24c21f675" title="Permalink to this equation">#</a></span>\[\begin{align}
  \text{ReAttention}(Q, K, V) = \text{Norm}(\theta^T(\text{softmax}(\frac{QK^T}{\sqrt{d_k}})))V
  \end{align}\]</div>
</li>
<li><p>Parallel attention <span id="id3">[<a class="reference internal" href="#id500" title="Hugo Touvron, Matthieu Cord, Alaaeldin El-Nouby, Jakob Verbeek, and Hervé Jégou. Three Things Everyone Should Know About Vision Transformers. In Shai Avidan, Gabriel Brostow, Moustapha Cissé, Giovanni Maria Farinella, and Tal Hassner, editors, Computer Vision – ECCV 2022, volume 13684, pages 497–515. Springer Nature Switzerland, Cham, 2022. URL: https://link.springer.com/10.1007/978-3-031-20053-3_29 (visited on 2023-11-10), doi:10.1007/978-3-031-20053-3_29.">Touvron <em>et al.</em>, 2022</a>]</span>: instead of stacking Transformer layers sequentially, you can run multiple (two is the recommendation) of them in parallel</p>
<!-- prettier-ignore -->
<div class="amsmath math notranslate nohighlight" id="equation-1d910609-2519-486b-bde1-52715eb58fdf">
<span class="eqno">(33)<a class="headerlink" href="#equation-1d910609-2519-486b-bde1-52715eb58fdf" title="Permalink to this equation">#</a></span>\[\begin{align}
  \mathbf{x'} &amp;= \text{MHA}_1(\mathbf{x}) + \text{MHA}_2(\mathbf{x})+ \mathbf{x} \\
  \mathbf{x''} &amp;= \text{MLP}_1(\mathbf{x'}) + \text{MLP}_2(\mathbf{x'})+ \mathbf{x'} \\
  \end{align}\]</div>
</li>
<li><p>LayerScale <span id="id4">[<a class="reference internal" href="#id499" title="Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and Hervé Jégou. Going deeper with Image Transformers. April 2021. URL: http://arxiv.org/abs/2103.17239 (visited on 2023-12-27), arXiv:2103.17239.">Touvron <em>et al.</em>, 2021</a>]</span>: apply diagonal weight matrices <span class="math notranslate nohighlight">\(W_{MHA}\)</span> and <span class="math notranslate nohighlight">\(W_{MLP}\)</span> to the output of the MHA and MLP layers in a transformer block (or, do a per-channel multiplication of the outputs before adding the residual connection), which improves training dynamics and allows for continued improvement when adding more layers to a ViT</p>
<!-- prettier-ignore -->
<div class="amsmath math notranslate nohighlight" id="equation-29713260-3f52-4595-9f14-e53ff1f6dd7a">
<span class="eqno">(34)<a class="headerlink" href="#equation-29713260-3f52-4595-9f14-e53ff1f6dd7a" title="Permalink to this equation">#</a></span>\[\begin{align}
  \mathbf{x'} &amp;= \mathbf{W}_{MHA} \, \text{MHA}(\mathbf{x}) + \mathbf{x} \\
  \mathbf{x''} &amp;= \mathbf{W}_{MLP} \, \text{MLP}(\mathbf{x'}) + \mathbf{x'} \\
  \end{align}\]</div>
</li>
<li><p>Branchformer <span id="id5">[<a class="reference internal" href="#id395" title="Yifan Peng, Siddharth Dalmia, Ian Lane, and Shinji Watanabe. Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding. July 2022. URL: http://arxiv.org/abs/2207.02971 (visited on 2023-12-20), arXiv:2207.02971.">Peng <em>et al.</em>, 2022</a>]</span>: replace the MLP with a convolutional gating MLP (cgMLP), which consists of a depth-wise convolution and linear gating, then merges the MHA and cgMLP outputs by concatenating them and linearly projecting down to the output dimension
<img alt="branchformer" src="../../_images/branchformer.png" /></p></li>
<li><p>Macaron net <span id="id6">[<a class="reference internal" href="#id323" title="Yiping Lu, Zhuohan Li, Di He, Zhiqing Sun, Bin Dong, Tao Qin, Liwei Wang, and Tie-Yan Liu. Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View. June 2019. URL: http://arxiv.org/abs/1906.02762 (visited on 2023-12-27), arXiv:1906.02762.">Lu <em>et al.</em>, 2019</a>]</span>: instead of MHA and then MLP, do half an MLP, then MHA, then the other half of the MLP, which improves performance</p>
<!-- prettier-ignore -->
<div class="amsmath math notranslate nohighlight" id="equation-4369e9d1-6b05-49a4-a895-f0d45d1534a4">
<span class="eqno">(35)<a class="headerlink" href="#equation-4369e9d1-6b05-49a4-a895-f0d45d1534a4" title="Permalink to this equation">#</a></span>\[\begin{align}
  \mathbf{x'} &amp;= \frac{1}{2}\text{MLP}_1(\mathbf{x}) + \mathbf{x} \\
  \mathbf{x''} &amp;= \text{MHA}(\mathbf{x'}) + \mathbf{x'} \\
  \mathbf{x'''} &amp;= \frac{1}{2}\text{MLP}_2(\mathbf{x''}) + \mathbf{x''} \\
  \end{align}\]</div>
</li>
<li><p>E-Branchformer <span id="id7">[<a class="reference internal" href="#id277" title="Kwangyoun Kim, Felix Wu, Yifan Peng, Jing Pan, Prashant Sridhar, Kyu J. Han, and Shinji Watanabe. E-Branchformer: Branchformer with Enhanced merging for speech recognition. October 2022. URL: http://arxiv.org/abs/2210.00077 (visited on 2023-12-27), arXiv:2210.00077.">Kim <em>et al.</em>, 2022</a>]</span>: merge global (MHA) and local (cgMLP) branches by concatenating them and then applying a depth-wise convolution with a residual connection before projecting back down</p>
<div class="amsmath math notranslate nohighlight" id="equation-f4345afc-6ae7-41a9-8c63-3d5724767b14">
<span class="eqno">(36)<a class="headerlink" href="#equation-f4345afc-6ae7-41a9-8c63-3d5724767b14" title="Permalink to this equation">#</a></span>\[\begin{align}
  \mathbf{x'} &amp;= \text{Concat}(\text{MHA}(\mathbf{x}), \text{cgMLP}(\mathbf{x})) \\
  \mathbf{x''} &amp;= \text{DwConv}(\mathbf{x'}) + \mathbf{x'} \\
  \mathbf{x'''} &amp;= \mathbf{W} \, \mathbf{x''}
  \end{align}\]</div>
</li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="vision-transformers">
<h1>Vision Transformers<a class="headerlink" href="#vision-transformers" title="Permalink to this heading">#</a></h1>
<section id="vision-transformers-dosovitskiy2021">
<h2>Vision Transformers <span id="id8">[<a class="reference internal" href="#id151" title="Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. June 2021. URL: http://arxiv.org/abs/2010.11929 (visited on 2023-10-12), arXiv:2010.11929.">Dosovitskiy <em>et al.</em>, 2021</a>]</span><a class="headerlink" href="#vision-transformers-dosovitskiy2021" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>ViTs are Transformers applied to images by splitting the image into patches, flattening them into a sequence of patches, embedding each patch into some higher dimensional space, then applying a standard transformer to the sequence</p></li>
<li><p>ViTs have much less inductive bias than CNNs, and spatial relations are learned through the positional embeddings, so ViTs tend to need more data to train</p></li>
<li><p>MLP layers are local and translationally equivariant, and the self-attention layers are global</p></li>
</ul>
</section>
<section id="axial-attention-ho2019">
<h2>Axial attention <span id="id9">[<a class="reference internal" href="#id230" title="Jonathan Ho, Nal Kalchbrenner, Dirk Weissenborn, and Tim Salimans. Axial Attention in Multidimensional Transformers. December 2019. URL: http://arxiv.org/abs/1912.12180 (visited on 2023-10-12), arXiv:1912.12180.">Ho <em>et al.</em>, 2019</a>]</span><a class="headerlink" href="#axial-attention-ho2019" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>axial attention works efficiently on high dimensional arrays (e.g., 3 spatial dimensions) by splitting the sequence into multiple axes and applying attention to each axis in parallel rather than patching the array (which quickly becomes unfeasible with <span class="math notranslate nohighlight">\(N^2\)</span> scaling in high dimensions)</p></li>
<li><p>implement by reshaping the input to put the axis you want to attend over in the second last position, then applying standard attention, then reshaping the input back, and repeating for each axis you want to attend over, and summing all the inputs</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pre-training">
<h1>Pre-training<a class="headerlink" href="#pre-training" title="Permalink to this heading">#</a></h1>
<section id="emergent-properties-in-self-supervised-vision-transformers-caron2021">
<h2>Emergent properties in self-supervised vision transformers <span id="id10">[<a class="reference internal" href="#id78" title="Mathilde Caron, Hugo Touvron, Ishan Misra, Herve Jegou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging Properties in Self-Supervised Vision Transformers. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV), 9630–9640. Montreal, QC, Canada, October 2021. IEEE. URL: https://ieeexplore.ieee.org/document/9709990/ (visited on 2023-12-27), doi:10.1109/ICCV48922.2021.00951.">Caron <em>et al.</em>, 2021</a>]</span><a class="headerlink" href="#emergent-properties-in-self-supervised-vision-transformers-caron2021" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>introduces DINO (self-distillation with no labels), which produces representations containing valuable segmentation information that can be used directly with a k-NN classifier (no fine-tuning or linear classifier) to produce high accuracy predictions on ImageNet</p></li>
<li><p>self-supervised learning process:</p></li>
</ul>
<ol class="arabic simple">
<li><p>create a student and a teacher network with the same architecture but different initializations</p></li>
<li><p>given an image, produce global views (random crops) and local views (random patches) of the image</p></li>
<li><p>give the global views to the teacher and all views to the student, and make them predict softmaxes over <span class="math notranslate nohighlight">\(K\)</span> dimensions</p></li>
<li><p>compute the cross-entropy loss between the student and teacher softmaxes and backpropagate through the student only</p></li>
<li><p>update the teacher by an exponential moving average (EMA) of the student weights <span class="math notranslate nohighlight">\(\theta_t \leftarrow \alpha \theta_t + (1 - \alpha) \theta_s\)</span></p></li>
</ol>
<ul class="simple">
<li><p>applying an (updating) centering and sharpening (with a temperature parameter on the softmax) to the teacher softmaxes prevents collapse (putting all probability in a single dimension or going to the uniform distribution)</p></li>
</ul>
<div class="docutils container" id="id11">
<dl class="citation">
<dt class="label" id="id78"><span class="brackets"><a class="fn-backref" href="#id10">CTM+21</a></span></dt>
<dd><p>Mathilde Caron, Hugo Touvron, Ishan Misra, Herve Jegou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging Properties in Self-Supervised Vision Transformers. In <em>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 9630–9640. Montreal, QC, Canada, October 2021. IEEE. URL: <a class="reference external" href="https://ieeexplore.ieee.org/document/9709990/">https://ieeexplore.ieee.org/document/9709990/</a> (visited on 2023-12-27), <a class="reference external" href="https://doi.org/10.1109/ICCV48922.2021.00951">doi:10.1109/ICCV48922.2021.00951</a>.</p>
</dd>
<dt class="label" id="id151"><span class="brackets"><a class="fn-backref" href="#id8">DBK+21</a></span></dt>
<dd><p>Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. June 2021. URL: <a class="reference external" href="http://arxiv.org/abs/2010.11929">http://arxiv.org/abs/2010.11929</a> (visited on 2023-10-12), <a class="reference external" href="https://arxiv.org/abs/2010.11929">arXiv:2010.11929</a>.</p>
</dd>
<dt class="label" id="id230"><span class="brackets"><a class="fn-backref" href="#id9">HKWS19</a></span></dt>
<dd><p>Jonathan Ho, Nal Kalchbrenner, Dirk Weissenborn, and Tim Salimans. Axial Attention in Multidimensional Transformers. December 2019. URL: <a class="reference external" href="http://arxiv.org/abs/1912.12180">http://arxiv.org/abs/1912.12180</a> (visited on 2023-10-12), <a class="reference external" href="https://arxiv.org/abs/1912.12180">arXiv:1912.12180</a>.</p>
</dd>
<dt class="label" id="id277"><span class="brackets"><a class="fn-backref" href="#id7">KWP+22</a></span></dt>
<dd><p>Kwangyoun Kim, Felix Wu, Yifan Peng, Jing Pan, Prashant Sridhar, Kyu J. Han, and Shinji Watanabe. E-Branchformer: Branchformer with Enhanced merging for speech recognition. October 2022. URL: <a class="reference external" href="http://arxiv.org/abs/2210.00077">http://arxiv.org/abs/2210.00077</a> (visited on 2023-12-27), <a class="reference external" href="https://arxiv.org/abs/2210.00077">arXiv:2210.00077</a>.</p>
</dd>
<dt class="label" id="id323"><span class="brackets"><a class="fn-backref" href="#id6">LLH+19</a></span></dt>
<dd><p>Yiping Lu, Zhuohan Li, Di He, Zhiqing Sun, Bin Dong, Tao Qin, Liwei Wang, and Tie-Yan Liu. Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View. June 2019. URL: <a class="reference external" href="http://arxiv.org/abs/1906.02762">http://arxiv.org/abs/1906.02762</a> (visited on 2023-12-27), <a class="reference external" href="https://arxiv.org/abs/1906.02762">arXiv:1906.02762</a>.</p>
</dd>
<dt class="label" id="id395"><span class="brackets"><a class="fn-backref" href="#id5">PDLW22</a></span></dt>
<dd><p>Yifan Peng, Siddharth Dalmia, Ian Lane, and Shinji Watanabe. Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding. July 2022. URL: <a class="reference external" href="http://arxiv.org/abs/2207.02971">http://arxiv.org/abs/2207.02971</a> (visited on 2023-12-20), <a class="reference external" href="https://arxiv.org/abs/2207.02971">arXiv:2207.02971</a>.</p>
</dd>
<dt class="label" id="id499"><span class="brackets"><a class="fn-backref" href="#id4">TCS+21</a></span></dt>
<dd><p>Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and Hervé Jégou. Going deeper with Image Transformers. April 2021. URL: <a class="reference external" href="http://arxiv.org/abs/2103.17239">http://arxiv.org/abs/2103.17239</a> (visited on 2023-12-27), <a class="reference external" href="https://arxiv.org/abs/2103.17239">arXiv:2103.17239</a>.</p>
</dd>
<dt class="label" id="id500"><span class="brackets"><a class="fn-backref" href="#id3">TCElNouby+22</a></span></dt>
<dd><p>Hugo Touvron, Matthieu Cord, Alaaeldin El-Nouby, Jakob Verbeek, and Hervé Jégou. Three Things Everyone Should Know About Vision Transformers. In Shai Avidan, Gabriel Brostow, Moustapha Cissé, Giovanni Maria Farinella, and Tal Hassner, editors, <em>Computer Vision – ECCV 2022</em>, volume 13684, pages 497–515. Springer Nature Switzerland, Cham, 2022. URL: <a class="reference external" href="https://link.springer.com/10.1007/978-3-031-20053-3_29">https://link.springer.com/10.1007/978-3-031-20053-3_29</a> (visited on 2023-11-10), <a class="reference external" href="https://doi.org/10.1007/978-3-031-20053-3_29">doi:10.1007/978-3-031-20053-3_29</a>.</p>
</dd>
<dt class="label" id="id509"><span class="brackets"><a class="fn-backref" href="#id1">VSP+17</a></span></dt>
<dd><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. 2017. URL: <a class="reference external" href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</a> (visited on 2023-10-14), <a class="reference external" href="https://arxiv.org/abs/1706.03762">arXiv:1706.03762</a>.</p>
</dd>
<dt class="label" id="id542"><span class="brackets"><a class="fn-backref" href="#id2">ZKJ+21</a></span></dt>
<dd><p>Daquan Zhou, Bingyi Kang, Xiaojie Jin, Linjie Yang, Xiaochen Lian, Zihang Jiang, Qibin Hou, and Jiashi Feng. DeepViT: Towards Deeper Vision Transformer. April 2021. URL: <a class="reference external" href="http://arxiv.org/abs/2103.11886">http://arxiv.org/abs/2103.11886</a> (visited on 2023-12-21), <a class="reference external" href="https://arxiv.org/abs/2103.11886">arXiv:2103.11886</a>.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="theory.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Theory</p>
      </div>
    </a>
    <a class="right-next"
       href="view_synthesis.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">View Synthesis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Attention</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-is-all-you-need-vaswani2017">Attention is all you need <span class="xref cite cite-p">Vaswani2017</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-variants">Attention variants</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#vision-transformers">Vision Transformers</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vision-transformers-dosovitskiy2021">Vision Transformers <span class="xref cite cite-p">Dosovitskiy2021</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#axial-attention-ho2019">Axial attention <span class="xref cite cite-p">Ho2019</span></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">Pre-training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#emergent-properties-in-self-supervised-vision-transformers-caron2021">Emergent properties in self-supervised vision transformers <span class="xref cite cite-p">Caron2021</span></a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Jeff Shen
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022-2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>